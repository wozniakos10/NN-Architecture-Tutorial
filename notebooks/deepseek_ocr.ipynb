{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQUNV-ABeKqW"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmZGFJzoeKFS",
        "outputId": "ceb72e8a-9f24-4c8a-90a3-38262a3f2a08"
      },
      "outputs": [],
      "source": [
        "#Using current pre-installed packages\n",
        "!pip install addict transformers==4.46.3 tokenizers==0.20.3 PyMuPDF img2pdf einops easydict Pillow numpy\n",
        "\n",
        "#If there is problem use:\n",
        "# pip install addict transformers==4.46.3 tokenizers==0.20.3 PyMuPDF img2pdf einops easydict Pillow numpy torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --extra-index-url https://download.pytorch.org/whl/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvvAEpbDeObU"
      },
      "source": [
        "## Clone DeepSeekOcr repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzLzaMLGLbd_",
        "outputId": "3ef9b61a-a0d8-4e3b-d9bf-a2bdc065eddb"
      },
      "outputs": [],
      "source": [
        "! git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw1qKXMqLfUN",
        "outputId": "d35ce8bf-ac14-4654-d304-23f42bac0233"
      },
      "outputs": [],
      "source": [
        "! git clone https://huggingface.co/deepseek-ai/DeepSeek-OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8KnOyDbNdg0"
      },
      "outputs": [],
      "source": [
        "!mv DeepSeek-OCR/ DeepSeek-OCR-local/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozpM5tDOeSbL"
      },
      "source": [
        "## Downloading images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGukF5ihOOLC"
      },
      "outputs": [],
      "source": [
        "!wget -O dogs.jpg https://images.wagwalkingweb.com/media/daily_wag/blog_articles/hero/1723114015.705158/popular-dogs-hero-1.jpg\n",
        "!wget -O polish_ocr.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/J%C3%B3zef_Ignacy_Kraszewski_-_Poezye_i_urywki_proz%C4%85.djvu/page35-1024px-J%C3%B3zef_Ignacy_Kraszewski_-_Poezye_i_urywki_proz%C4%85.djvu.jpg\n",
        "!wget -O table_markdown.png https://ksiegujesie.pl/wp-content/uploads/2023/12/cennik-2024.png\n",
        "!wget -O lion.jpg https://i.natgeofe.com/k/1d33938b-3d02-4773-91e3-70b113c3b8c7/lion-male-roar.jpg?wp=1&w=1084.125&h=609\n",
        "!wget -O figure.png https://clauswilke.com/dataviz/visualizing_distributions_I_files/figure-html/titanic-age-stacked-hist-1.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL9xFuzTeU-i"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zn2vx-nPlUW"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "from IPython.display import Image, display\n",
        "from PIL import Image, ImageDraw\n",
        "import sys\n",
        "from io import StringIO\n",
        "from typing import Optional\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C9Q3kU2eW-e"
      },
      "source": [
        "## Output Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "800704ec"
      },
      "outputs": [],
      "source": [
        "################################\n",
        "############UTILS###############\n",
        "################################\n",
        "\n",
        "# Bounding box constants\n",
        "\n",
        "# catch all <|det|> a <|/det|>\n",
        "BOUNDING_BOX_CONTAINER_PATTERN = re.compile(\n",
        "    r\"<\\|det\\|>(.*?)<\\|/det\\|>\",\n",
        "    re.DOTALL\n",
        ")\n",
        "\n",
        "# catch all bb\n",
        "BOX_COORD_PATTERN = re.compile(\n",
        "    r\"\\[(\\d+),\\s*(\\d+),\\s*(\\d+),\\s*(\\d+)\\]\"\n",
        ")\n",
        "\n",
        "BOUNDING_BOX_COLOR = \"red\"\n",
        "BOUNDING_BOX_WIDTH = 3\n",
        "NORMALIZATION_FACTOR = 1000\n",
        "\n",
        "\n",
        "def parse_ocr_output(raw_output: str) -> str:\n",
        "    \"\"\"Parse raw OCR output to remove debug info and format cleanly\"\"\"\n",
        "    lines = raw_output.split('\\n')\n",
        "    parsed_lines = []\n",
        "    in_content = False\n",
        "\n",
        "    # Patterns to skip (debug/metadata)\n",
        "    skip_patterns = [\n",
        "        'BASE:', 'PATCHES:', 'NO PATCHES', 'directly resize',\n",
        "        'image size:', 'valid image tokens:', 'output texts tokens',\n",
        "        'compression ratio:', 'save results:', '====', '===',\n",
        "    ]\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "\n",
        "        # Skip empty lines and debug patterns\n",
        "        if not stripped or any(pattern in line for pattern in skip_patterns):\n",
        "            continue\n",
        "\n",
        "        # Handle ref/det structured data\n",
        "        if '<|ref|>' in line:\n",
        "            # Extract all reference-detection pairs from this line\n",
        "            import re\n",
        "            pattern = r'<\\|ref\\|>(.*?)<\\|/ref\\|>(?:<\\|det\\|>\\[\\[(.*?)\\]\\]<\\|/det\\|>)?'\n",
        "            matches = re.findall(pattern, line)\n",
        "\n",
        "            if matches:\n",
        "                for ref_text, coords in matches:\n",
        "                    if coords:\n",
        "                        # Format with coordinates\n",
        "                        parsed_lines.append(f\"• **{ref_text}** → `[{coords}]`\")\n",
        "                    else:\n",
        "                        # Just the reference text\n",
        "                        parsed_lines.append(ref_text.strip())\n",
        "            continue\n",
        "\n",
        "        # Regular content - add as is\n",
        "        parsed_lines.append(stripped)\n",
        "\n",
        "    result = '\\n'.join(parsed_lines)\n",
        "    return result if result.strip() else raw_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Main function\n",
        "# -----------------------\n",
        "def extract_and_draw_bounding_boxes(text_result: str, original_image: Image.Image) -> Optional[Image.Image]:\n",
        "    \"\"\"\n",
        "    Extract bounding box coordinates from text_result and draw them on the image.\n",
        "    \"\"\"\n",
        "    all_boxes = []\n",
        "\n",
        "    # znajdź wszystkie fragmenty między <|det|> a <|/det|>\n",
        "    for container in BOUNDING_BOX_CONTAINER_PATTERN.findall(text_result):\n",
        "        # znajdź wszystkie [x1, y1, x2, y2] w środku\n",
        "        boxes = BOX_COORD_PATTERN.findall(container)\n",
        "        for coords in boxes:\n",
        "            all_boxes.append(tuple(map(int, coords)))\n",
        "\n",
        "    if not all_boxes:\n",
        "        print(\"⚠️ No bounding boxes found.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"✅ Found {len(all_boxes)} bounding boxes: {all_boxes}\")\n",
        "\n",
        "    # rysowanie\n",
        "    image_with_bboxes = original_image.copy()\n",
        "    draw = ImageDraw.Draw(image_with_bboxes)\n",
        "    w, h = original_image.size\n",
        "    w_scale = w / NORMALIZATION_FACTOR\n",
        "    h_scale = h / NORMALIZATION_FACTOR\n",
        "\n",
        "    for (x1n, y1n, x2n, y2n) in all_boxes:\n",
        "        x1 = int(x1n * w_scale)\n",
        "        y1 = int(y1n * h_scale)\n",
        "        x2 = int(x2n * w_scale)\n",
        "        y2 = int(y2n * h_scale)\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=BOUNDING_BOX_COLOR, width=BOUNDING_BOX_WIDTH)\n",
        "\n",
        "    return image_with_bboxes\n",
        "\n",
        "\n",
        "def load_img(path):\n",
        "  print(path)\n",
        "  return Image.open(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAlGO-Z8ecNa"
      },
      "source": [
        "## Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ5aXRPELiS5",
        "outputId": "3dae5eab-2e75-407f-95bf-83cc0d8eace0"
      },
      "outputs": [],
      "source": [
        "# LOADING MODEL\n",
        "model_name = './DeepSeek-OCR-local/'\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\" Using CUDA GPU\")\n",
        "    model = AutoModel.from_pretrained(\n",
        "    model_name,\n",
        "    # flash attention requires modern hardware to utilize\n",
        "    # FlashAttention requires Ampere or newer:\n",
        "\n",
        "    # Works on: A100, RTX 3090, RTX 4080/4090, H100, L40\n",
        "\n",
        "    # Doesn’t work on: T4, V100, RTX 2080, GTX 1080\n",
        "    # _attn_implementation='flash_attention_2',\n",
        "    _attn_implementation='eager',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    use_safetensors=True\n",
        ")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = model.eval().cuda()\n",
        "else:\n",
        "    #default hugginhface implementation have cuda hardcoded and doesn't support cpu\n",
        "    # to use cpu have to modify modelling_deepseekocr.py file like in this disscusion\n",
        "    # https://huggingface.co/deepseek-ai/DeepSeek-OCR/discussions/21/files#d2h-465181\n",
        "    print(\"Using CPU (no GPU detected)\")\n",
        "    model = AutoModel.from_pretrained(model_name, _attn_implementation='eager', trust_remote_code=True, use_safetensors=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = model.eval().to(torch.bfloat16)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Model and tokenizer loaded in {end - start:.2f} seconds.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIVY3oBkeguz"
      },
      "source": [
        "## Model Inference\n",
        "Here are the prompt examples that you can play with:\n",
        "\n",
        "\n",
        "document: <image>\\n<|grounding|>Convert the document to markdown.\n",
        "\n",
        "other image: <image>\\n<|grounding|>OCR this image.\n",
        "\n",
        "without layouts: <image>\\nFree OCR.\n",
        "\n",
        "figures in document: <image>\\nParse the figure.\n",
        "\n",
        "general: <image>\\nDescribe this image in detail.\n",
        "\n",
        "rec: <image>\\nLocate <|ref|>xxxx<|/ref|> in the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8GAvA2_Oo1H"
      },
      "outputs": [],
      "source": [
        "\n",
        "def perform_vllm(model,prompt,img_path,output_path,draw_bbox=True):\n",
        "  #prompts examples:\n",
        "  # document: <image>\\n<|grounding|>Convert the document to markdown.\n",
        "  # other image: <image>\\n<|grounding|>OCR this image.\n",
        "  # without layouts: <image>\\nFree OCR.\n",
        "  # figures in document: <image>\\nParse the figure.\n",
        "  # general: <image>\\nDescribe this image in detail.\n",
        "  # rec: <image>\\nLocate <|ref|>xxxx<|/ref|> in the image.\n",
        "  # '先天下之忧而忧'\n",
        "\n",
        "\n",
        "  image = load_img(img_path)\n",
        "\n",
        "  #Different model sizes\n",
        "  # Tiny: base_size = 512, image_size = 512, crop_mode = False\n",
        "  # Small: base_size = 640, image_size = 640, crop_mode = False\n",
        "  # Base: base_size = 1024, image_size = 1024, crop_mode = False\n",
        "  # Large: base_size = 1280, image_size = 1280, crop_mode = False\n",
        "\n",
        "  # Gundam: base_size = 1024, image_size = 640, crop_mode = True\n",
        "  start = time.time()\n",
        "  # Capture stdout\n",
        "  captured_output = StringIO()\n",
        "  old_stdout = sys.stdout\n",
        "  sys.stdout = captured_output\n",
        "\n",
        "\n",
        "  #locally it saved data to disk, but it doesn't work in colab\n",
        "  # so have to take data from stdout\n",
        "  try:\n",
        "    result = model.infer(tokenizer, prompt=prompt, image_file=img_path, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)\n",
        "  finally:\n",
        "    sys.stdout = old_stdout\n",
        "\n",
        "  # Get captured text\n",
        "  console_output = captured_output.getvalue()\n",
        "  text_result = console_output if console_output else str(result)\n",
        "  parsed_result = parse_ocr_output(text_result)\n",
        "  end = time.time()\n",
        "  print(f\"Inference completed in {end - start:.2f} seconds.\")\n",
        "  if draw_bbox:\n",
        "    # Try to extract and draw bounding boxes\n",
        "    result_image = extract_and_draw_bounding_boxes(text_result, image)\n",
        "    display(result_image)\n",
        "  else:\n",
        "    display(image)\n",
        "  print(f\"Raw vllm result:{text_result}\\n\\n\")\n",
        "  # print(f\"Parsed Vllm result:\\n{parsed_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtsrpGlXekgJ"
      },
      "source": [
        "## OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "Cn80r3ZaRLj4",
        "outputId": "74ff61e9-e439-4365-b7e5-7b168e82b116"
      },
      "outputs": [],
      "source": [
        "perform_vllm(model,prompt=\"<image>\\nFree OCR.\",\n",
        "             img_path=\"polish_ocr.jpg\", output_path=\"output/polish_ocr\", draw_bbox=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exYEkSIXjGQt"
      },
      "source": [
        "## Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OSxHxDHYjHvi",
        "outputId": "385516aa-7f23-4652-a11f-648b7cbb12ea"
      },
      "outputs": [],
      "source": [
        "perform_vllm(model,prompt=\"<image>\\n<|grounding|>Convert the document to markdown.\",\n",
        "             img_path=\"table_markdown.png\", output_path=\"output/markdown\", draw_bbox=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5dR4XV9emoB"
      },
      "source": [
        "## Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "gevA7lo7RMRl",
        "outputId": "02a0b45b-ebd5-4b55-d365-5c7706ffe8b8"
      },
      "outputs": [],
      "source": [
        "perform_vllm(model,prompt=\"<image>\\nLocate <|ref|>dog<|/ref|> in the image.\",\n",
        "             img_path=\"dogs.jpg\", output_path=\"output/dogs\", draw_bbox=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB6J0cNzg4gc"
      },
      "source": [
        "## Image Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vK1vEG_5YHyz",
        "outputId": "012d9cf4-2632-45fe-8f10-59d202232f24"
      },
      "outputs": [],
      "source": [
        "perform_vllm(model,prompt=\"<image>\\nDescribe this image in detail.\",\n",
        "             img_path=\"lion.jpg\", output_path=\"output/lion\", draw_bbox=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URaHZTiik4wj"
      },
      "source": [
        "## Parse Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sJ936owDfUXy",
        "outputId": "0f33c737-5298-4a05-d22f-1cb9f0f3149d"
      },
      "outputs": [],
      "source": [
        "perform_vllm(model,prompt=\"<image>\\nParse the figure.\",\n",
        "             img_path=\"figure.png\", output_path=\"output/figure\", draw_bbox=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPvfwRWmk_TR"
      },
      "source": [
        "## Your examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp3zjgMwhL6v"
      },
      "outputs": [],
      "source": [
        "perform_vllm(model,prompt=\"CHOOSE PROMPT FOR YOU NEED\",\n",
        "             img_path=\"INPUT_IMAGE_PATH\", output_path=\"OUTPUT_PATH\", draw_bbox=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQWmEXqLsnm2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
